{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch_geometric_temporal.signal import StaticGraphTemporalSignal\n",
    "import torch\n",
    "\n",
    "class StaticSP500DatasetLoader(object):\n",
    "    def __init__(self, correlation_type='pearsons'):\n",
    "        self._read_csv(correlation_type)\n",
    "\n",
    "    def _read_csv(self, correlation_type):\n",
    "        self._correlation_matrix = np.fromfile(f's&p500_{correlation_type}.csv', sep=',')\n",
    "        N = int(np.sqrt(len(self._correlation_matrix)))\n",
    "        self._correlation_matrix = self._correlation_matrix.reshape(N, N)\n",
    "        _correlation_threshold = 0.9\n",
    "        self._correlation_matrix[self._correlation_matrix < _correlation_threshold] = 0\n",
    "        \n",
    "        df = pd.read_csv('s&p500.csv')\n",
    "        df = df.set_index('Date')\n",
    "        data = torch.from_numpy(df.to_numpy()).to(torch.float32)\n",
    "\n",
    "        # Round data size to nearest multiple of batch_size\n",
    "        days_in_quarter = 64\n",
    "        num_quarters = data.size(0) // days_in_quarter\n",
    "        num_days = num_quarters * days_in_quarter\n",
    "        data = data[:num_days]\n",
    "        \n",
    "        # z-score normalization with training data following GERU\n",
    "        train_days = int(0.8 * num_quarters) * days_in_quarter\n",
    "        data = (data - data[:train_days].mean(dim=0)) / data[:train_days].std(dim=0)\n",
    "        data = data.numpy()\n",
    "        pd.DataFrame(data).to_csv('s&p500_z_scores.csv')\n",
    "        self._dataset = data\n",
    "\n",
    "    def _get_edges(self):\n",
    "        self._edges = np.array(self._correlation_matrix.nonzero())\n",
    "\n",
    "    def _get_edge_weights(self):\n",
    "        self._edge_weights = self._correlation_matrix[self._correlation_matrix > 0]\n",
    "\n",
    "    def _get_targets_and_features(self):\n",
    "        stacked_target = self._dataset\n",
    "        self.features = [\n",
    "            stacked_target[i : i + self.lags, :].T\n",
    "            for i in range(stacked_target.shape[0] - self.lags)\n",
    "        ]\n",
    "        # predict next-day stock movement\n",
    "        self.targets = [\n",
    "            ((stacked_target[i + self.lags, :] > stacked_target[i + self.lags - 1, :]).astype(float)).T\n",
    "            for i in range(stacked_target.shape[0] - self.lags)\n",
    "        ]\n",
    "\n",
    "    def get_dataset(self, lags: int) -> StaticGraphTemporalSignal:\n",
    "        \"\"\"Returning the data iterator.\n",
    "\n",
    "        Args types:\n",
    "            * **lags** *(int)* - The number of time lags.\n",
    "        Return types:\n",
    "            * **dataset** *(StaticGraphTemporalSignal)*\n",
    "        \"\"\"\n",
    "        self.lags = lags\n",
    "        self._get_edges()\n",
    "        self._get_edge_weights()\n",
    "        self._get_targets_and_features()\n",
    "        dataset = StaticGraphTemporalSignal(\n",
    "            self._edges, self._edge_weights, self.features, self.targets\n",
    "        )\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric_temporal.signal import temporal_signal_split\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "loader = StaticSP500DatasetLoader()\n",
    "\n",
    "lags = 63\n",
    "\n",
    "dataset = loader.get_dataset(lags)\n",
    "\n",
    "train_dataset, test_val_dataset = temporal_signal_split(dataset, train_ratio=0.8)\n",
    "val_dataset, test_dataset = temporal_signal_split(test_val_dataset, train_ratio=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from torcheval.metrics.functional import binary_f1_score, binary_accuracy\n",
    "\n",
    "def accuracy(y_hats, ys):\n",
    "    return binary_accuracy(y_hats.flatten(), ys.flatten()).item()\n",
    "\n",
    "def f1(y_hats, ys):\n",
    "    return binary_f1_score(y_hats.flatten(), ys.flatten()).item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric_temporal.nn.recurrent import DCRNN\n",
    "\n",
    "class RecurrentGCN(torch.nn.Module):\n",
    "    def __init__(self, node_features):\n",
    "        super(RecurrentGCN, self).__init__()\n",
    "        self.recurrent = DCRNN(node_features, 64, 1)\n",
    "        self.linear = torch.nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        h = self.recurrent(x, edge_index, edge_weight)\n",
    "        h = F.relu(h)\n",
    "        return F.sigmoid(self.linear(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkevinxli\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/teamspace/studios/this_studio/cs224w-stock-market-prediction/wandb/run-20241203_183317-euoghluy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kevinxli/cs224w-stock-market-prediction/runs/euoghluy' target=\"_blank\">comic-forest-78</a></strong> to <a href='https://wandb.ai/kevinxli/cs224w-stock-market-prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kevinxli/cs224w-stock-market-prediction' target=\"_blank\">https://wandb.ai/kevinxli/cs224w-stock-market-prediction</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kevinxli/cs224w-stock-market-prediction/runs/euoghluy' target=\"_blank\">https://wandb.ai/kevinxli/cs224w-stock-market-prediction/runs/euoghluy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, val/acc: 0.5113517642021179, val/f1: 0.6731860041618347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:08<02:37,  8.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, val/acc: 0.49059250950813293, val/f1: 0.2619778513908386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:16<02:24,  8.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, val/acc: 0.49188289046287537, val/f1: 0.38864120841026306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:24<02:16,  8.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, val/acc: 0.5120143890380859, val/f1: 0.6772612929344177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:32<02:07,  7.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, val/acc: 0.5119620561599731, val/f1: 0.6770516633987427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [00:39<01:58,  7.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, val/acc: 0.512005627155304, val/f1: 0.6770040988922119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:47<01:50,  7.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, val/acc: 0.5118748545646667, val/f1: 0.6770461201667786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [00:55<01:43,  7.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, val/acc: 0.5107763409614563, val/f1: 0.6721357703208923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [01:03<01:35,  7.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, val/acc: 0.5064954161643982, val/f1: 0.6322259306907654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [01:11<01:27,  7.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, val/acc: 0.49844807386398315, val/f1: 0.5378398299217224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [01:19<01:19,  7.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, val/acc: 0.4962073564529419, val/f1: 0.4733162820339203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [01:27<01:11,  7.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, val/acc: 0.49514368176460266, val/f1: 0.4511946737766266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [01:35<01:03,  7.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, val/acc: 0.49565809965133667, val/f1: 0.46159714460372925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [01:43<00:55,  7.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, val/acc: 0.49763724207878113, val/f1: 0.4948493540287018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [01:51<00:47,  7.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, val/acc: 0.49851781129837036, val/f1: 0.5426512956619263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [01:59<00:39,  7.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, val/acc: 0.5034438967704773, val/f1: 0.593897819519043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [02:06<00:31,  7.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, val/acc: 0.5066523551940918, val/f1: 0.6339412331581116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [02:14<00:23,  7.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, val/acc: 0.5082653164863586, val/f1: 0.6553789377212524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [02:22<00:15,  7.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, val/acc: 0.5100875496864319, val/f1: 0.6655118465423584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [02:30<00:07,  7.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, val/acc: 0.5108373165130615, val/f1: 0.6696266531944275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:38<00:00,  7.90s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import copy\n",
    "\n",
    "model = RecurrentGCN(node_features = lags).to(device)\n",
    "\n",
    "lr = 1e-3\n",
    "num_epochs = 20\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "track_with_wandb = True\n",
    "\n",
    "if track_with_wandb:\n",
    "    wandb.init(project=\"cs224w-stock-market-prediction\", config={\n",
    "        \"dataset\": \"S&P500\",\n",
    "        \"learning_rate\": lr,\n",
    "        \"epochs\": num_epochs,\n",
    "        \"architecture\": \"DCRNN\",\n",
    "    })\n",
    "\n",
    "best_f1 = 0\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train()\n",
    "    y_hats, ys = zip(*[(model(snapshot.x.to(device), snapshot.edge_index.to(device), snapshot.edge_attr.to(device)), snapshot.y)\n",
    "                       for time, snapshot in enumerate(train_dataset)])\n",
    "    y_hats, ys = torch.stack(list(y_hats)).squeeze().to(device), torch.stack(list(ys)).to(device)\n",
    "\n",
    "    if track_with_wandb:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            train_acc = accuracy(y_hats, ys)\n",
    "            train_f1 = f1(y_hats, ys) \n",
    "            val_y_hats, val_ys = zip(*[(model(snapshot.x.to(device), snapshot.edge_index.to(device), snapshot.edge_attr.to(device)), snapshot.y)\n",
    "                       for time, snapshot in enumerate(val_dataset)])\n",
    "            val_y_hats, val_ys = torch.stack(list(val_y_hats)).squeeze().to(device), torch.stack(list(val_ys)).to(device)\n",
    "            val_acc = accuracy(val_y_hats, val_ys)\n",
    "            val_f1 = f1(val_y_hats, val_ys)\n",
    "            wandb.log({\"epoch\": epoch,\n",
    "                    \"train/acc\": train_acc,\n",
    "                    \"train/f1\": train_f1,\n",
    "                    \"val/acc\": val_acc,\n",
    "                    \"val/f1\": val_f1 })\n",
    "            print(f'Epoch {epoch}, val/acc: {val_acc}, val/f1: {val_f1}')\n",
    "            if val_f1 > best_f1:\n",
    "                best_f1 = val_f1\n",
    "                torch.save(model.state_dict(), 'dcrnn_best_model.pth')\n",
    "\n",
    "    model.train()\n",
    "    loss = F.binary_cross_entropy(y_hats, ys)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if track_with_wandb:\n",
    "    best_model = RecurrentGCN(node_features = lags).to(device)\n",
    "    best_model.load_state_dict(torch.load('dcrnn_best_model.pth', weights_only=True))\n",
    "    best_model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_hats, ys = zip(*[(best_model(snapshot.x.to(device), snapshot.edge_index.to(device), snapshot.edge_attr.to(device)), snapshot.y)\n",
    "                       for time, snapshot in enumerate(test_dataset)])\n",
    "        y_hats, ys = torch.stack(list(y_hats)).squeeze().to(device), torch.stack(list(ys)).to(device)\n",
    "        wandb.log({\"epoch\": epoch,\n",
    "                \"test/acc\": accuracy(y_hats, ys),\n",
    "                \"test/f1\": f1(y_hats, ys) })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stock",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
