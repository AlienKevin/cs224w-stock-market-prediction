{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch_geometric_temporal.signal import StaticGraphTemporalSignal\n",
    "import torch\n",
    "\n",
    "class StaticSP500DatasetLoader(object):\n",
    "    def __init__(self, correlation_type='pearsons'):\n",
    "        self._read_csv(correlation_type)\n",
    "\n",
    "    def _read_csv(self, correlation_type):\n",
    "        self._correlation_matrix = np.fromfile(f's&p500_{correlation_type}.csv', sep=',')\n",
    "        N = int(np.sqrt(len(self._correlation_matrix)))\n",
    "        self._correlation_matrix = self._correlation_matrix.reshape(N, N)\n",
    "        _correlation_threshold = 0.9\n",
    "        self._correlation_matrix[self._correlation_matrix < _correlation_threshold] = 0\n",
    "        \n",
    "        df = pd.read_csv('s&p500.csv')\n",
    "        df = df.set_index('Date')\n",
    "        data = torch.from_numpy(df.to_numpy()).to(torch.float32)\n",
    "\n",
    "        # Round data size to nearest multiple of batch_size\n",
    "        days_in_quarter = 64\n",
    "        num_quarters = data.size(0) // days_in_quarter\n",
    "        num_days = num_quarters * days_in_quarter\n",
    "        data = data[:num_days]\n",
    "        \n",
    "        # z-score normalization with training data following GERU\n",
    "        train_days = int(0.8 * num_quarters) * days_in_quarter\n",
    "        data = (data - data[:train_days].mean(dim=0)) / data[:train_days].std(dim=0)\n",
    "\n",
    "        pd.DataFrame(data).to_csv('s&p500_z_scores.csv')\n",
    "\n",
    "        self._dataset = data.numpy()\n",
    "\n",
    "    def _get_edges(self):\n",
    "        self._edges = np.array(self._correlation_matrix.nonzero())\n",
    "\n",
    "    def _get_edge_weights(self):\n",
    "        self._edge_weights = self._correlation_matrix[self._correlation_matrix > 0]\n",
    "\n",
    "    def _get_targets_and_features(self):\n",
    "        stacked_target = self._dataset\n",
    "        self.features = [\n",
    "            stacked_target[i : i + self.lags, :].T\n",
    "            for i in range(stacked_target.shape[0] - self.lags)\n",
    "        ]\n",
    "        # predict next-day stock price directly\n",
    "        self.targets = [\n",
    "            (stacked_target[i + self.lags, :]).T\n",
    "            for i in range(stacked_target.shape[0] - self.lags)\n",
    "        ]\n",
    "\n",
    "    def get_dataset(self, lags: int) -> StaticGraphTemporalSignal:\n",
    "        \"\"\"Returning the data iterator.\n",
    "\n",
    "        Args types:\n",
    "            * **lags** *(int)* - The number of time lags.\n",
    "        Return types:\n",
    "            * **dataset** *(StaticGraphTemporalSignal)*\n",
    "        \"\"\"\n",
    "        self.lags = lags\n",
    "        self._get_edges()\n",
    "        self._get_edge_weights()\n",
    "        self._get_targets_and_features()\n",
    "        dataset = StaticGraphTemporalSignal(\n",
    "            self._edges, self._edge_weights, self.features, self.targets\n",
    "        )\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric_temporal.signal import temporal_signal_split\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "loader = StaticSP500DatasetLoader()\n",
    "\n",
    "lags = 63\n",
    "\n",
    "dataset = loader.get_dataset(lags)\n",
    "\n",
    "train_dataset, test_val_dataset = temporal_signal_split(dataset, train_ratio=0.8)\n",
    "val_dataset, test_dataset = temporal_signal_split(test_val_dataset, train_ratio=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from torcheval.metrics.functional import binary_f1_score\n",
    "\n",
    "def mse(y_hats, ys):\n",
    "    return torch.nn.functional.mse_loss(y_hats, ys)\n",
    "\n",
    "def rmse(y_hats, ys):\n",
    "    return math.sqrt(mse(y_hats, ys))\n",
    "\n",
    "def mae(y_hats, ys):\n",
    "    return torch.nn.functional.l1_loss(y_hats, ys)\n",
    "\n",
    "def accuracy(y_hats, y_prevs, ys):\n",
    "    return ((y_hats > y_prevs) == (ys > y_prevs)).sum().item() / y_hats.numel()\n",
    "\n",
    "def f1(y_hats, y_prevs, ys):\n",
    "    return binary_f1_score((y_hats > y_prevs).int().flatten(), (ys > y_prevs).int().flatten(), threshold=1).item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric_temporal.nn.recurrent import DCRNN\n",
    "\n",
    "class RecurrentGCN(torch.nn.Module):\n",
    "    def __init__(self, node_features):\n",
    "        super(RecurrentGCN, self).__init__()\n",
    "        self.recurrent = DCRNN(node_features, 32, 1)\n",
    "        self.linear = torch.nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        h = self.recurrent(x, edge_index, edge_weight)\n",
    "        h = F.relu(h)\n",
    "        h = self.linear(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkevinxli\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Volumes/crucialx9/classes/fall2024/cs224w/stock/wandb/run-20241203_001738-5u5kp37x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kevinxli/cs224w-stock-market-prediction/runs/5u5kp37x' target=\"_blank\">dry-resonance-55</a></strong> to <a href='https://wandb.ai/kevinxli/cs224w-stock-market-prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kevinxli/cs224w-stock-market-prediction' target=\"_blank\">https://wandb.ai/kevinxli/cs224w-stock-market-prediction</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kevinxli/cs224w-stock-market-prediction/runs/5u5kp37x' target=\"_blank\">https://wandb.ai/kevinxli/cs224w-stock-market-prediction/runs/5u5kp37x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [07:15<07:29, 17.98s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "model = RecurrentGCN(node_features = lags).to(device)\n",
    "\n",
    "lr = 0.001\n",
    "num_epochs = 50\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "track_with_wandb = True\n",
    "\n",
    "if track_with_wandb:\n",
    "    wandb.init(project=\"cs224w-stock-market-prediction\", config={\n",
    "        \"dataset\": \"S&P500\",\n",
    "        \"learning_rate\": lr,\n",
    "        \"epochs\": num_epochs,\n",
    "        \"architecture\": \"DCRNN\",\n",
    "    })\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train()\n",
    "    y_hats, ys, y_prevs = zip(*[(model(snapshot.x, snapshot.edge_index, snapshot.edge_attr), snapshot.y, snapshot.x[:,-1])\n",
    "                       for time, snapshot in enumerate(train_dataset)])\n",
    "    y_hats, ys, y_prevs = torch.stack(list(y_hats)).squeeze(), torch.stack(list(ys)), torch.stack(list(y_prevs))\n",
    "    loss = mse(y_hats, ys)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if track_with_wandb:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            wandb.log({\"epoch\": epoch,\n",
    "                    \"train/rmse\": rmse(y_hats, ys),\n",
    "                    \"train/mae\": mae(y_hats, ys),\n",
    "                    \"train/acc\": accuracy(y_hats, y_prevs, ys),\n",
    "                    \"train/f1\": f1(y_hats, y_prevs, ys) })\n",
    "            y_hats, ys, y_prevs = zip(*[(model(snapshot.x, snapshot.edge_index, snapshot.edge_attr), snapshot.y, snapshot.x[:,-1])\n",
    "                       for time, snapshot in enumerate(val_dataset)])\n",
    "            y_hats, ys, y_prevs = torch.stack(list(y_hats)).squeeze(), torch.stack(list(ys)), torch.stack(list(y_prevs))\n",
    "            wandb.log({\"epoch\": epoch,\n",
    "                    \"val/rmse\": rmse(y_hats, ys),\n",
    "                    \"val/mae\": mae(y_hats, ys),\n",
    "                    \"val/acc\": accuracy(y_hats, y_prevs, ys),\n",
    "                    \"val/f1\": f1(y_hats, y_prevs, ys) })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if track_with_wandb:\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_hats, ys, y_prevs = zip(*[(model(snapshot.x, snapshot.edge_index, snapshot.edge_attr), snapshot.y, snapshot.x[:,-1])\n",
    "                       for time, snapshot in enumerate(test_dataset)])\n",
    "        y_hats, ys, y_prevs = torch.stack(list(y_hats)).squeeze(), torch.stack(list(ys)), torch.stack(list(y_prevs))\n",
    "        wandb.log({\"epoch\": epoch,\n",
    "                \"test/rmse\": rmse(y_hats, ys),\n",
    "                \"test/mae\": mae(y_hats, ys),\n",
    "                \"test/acc\": accuracy(y_hats, y_prevs, ys),\n",
    "                \"test/f1\": f1(y_hats, y_prevs, ys) })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stock",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
