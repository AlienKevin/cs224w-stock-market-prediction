{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from typing import Sequence, Union\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "\n",
    "Edge_Index = Union[np.ndarray, None]\n",
    "Edge_Weight = Union[np.ndarray, None]\n",
    "Node_Features = Sequence[Union[np.ndarray, None]]\n",
    "Targets = Sequence[Union[np.ndarray, None]]\n",
    "Additional_Features = Sequence[np.ndarray]\n",
    "\n",
    "# Copied from PyG temporal rather than imported as the library has dependency issues\n",
    "# https://pytorch-geometric-temporal.readthedocs.io/en/latest/_modules/torch_geometric_temporal/signal/static_graph_temporal_signal.html#StaticGraphTemporalSignal\n",
    "class StaticGraphTemporalSignal(object):\n",
    "    r\"\"\"A data iterator object to contain a static graph with a dynamically\n",
    "    changing constant time difference temporal feature set (multiple signals).\n",
    "    The node labels (target) are also temporal. The iterator returns a single\n",
    "    constant time difference temporal snapshot for a time period (e.g. day or week).\n",
    "    This single temporal snapshot is a Pytorch Geometric Data object. Between two\n",
    "    temporal snapshots the features and optionally passed attributes might change.\n",
    "    However, the underlying graph is the same.\n",
    "\n",
    "    Args:\n",
    "        edge_index (Numpy array): Index tensor of edges.\n",
    "        edge_weight (Numpy array): Edge weight tensor.\n",
    "        features (Sequence of Numpy arrays): Sequence of node feature tensors.\n",
    "        targets (Sequence of Numpy arrays): Sequence of node label (target) tensors.\n",
    "        **kwargs (optional Sequence of Numpy arrays): Sequence of additional attributes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        edge_index: Edge_Index,\n",
    "        edge_weight: Edge_Weight,\n",
    "        features: Node_Features,\n",
    "        targets: Targets,\n",
    "        **kwargs: Additional_Features\n",
    "    ):\n",
    "        self.edge_index = edge_index\n",
    "        self.edge_weight = edge_weight\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        self.additional_feature_keys = []\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "            self.additional_feature_keys.append(key)\n",
    "        self._check_temporal_consistency()\n",
    "        self._set_snapshot_count()\n",
    "\n",
    "    def _check_temporal_consistency(self):\n",
    "        assert len(self.features) == len(\n",
    "            self.targets\n",
    "        ), \"Temporal dimension inconsistency.\"\n",
    "        for key in self.additional_feature_keys:\n",
    "            assert len(self.targets) == len(\n",
    "                getattr(self, key)\n",
    "            ), \"Temporal dimension inconsistency.\"\n",
    "\n",
    "    def _set_snapshot_count(self):\n",
    "        self.snapshot_count = len(self.features)\n",
    "\n",
    "    def _get_edge_index(self):\n",
    "        if self.edge_index is None:\n",
    "            return self.edge_index\n",
    "        else:\n",
    "            return torch.LongTensor(self.edge_index)\n",
    "\n",
    "    def _get_edge_weight(self):\n",
    "        if self.edge_weight is None:\n",
    "            return self.edge_weight\n",
    "        else:\n",
    "            return torch.FloatTensor(self.edge_weight)\n",
    "\n",
    "    def _get_features(self, time_index: int):\n",
    "        if self.features[time_index] is None:\n",
    "            return self.features[time_index]\n",
    "        else:\n",
    "            return torch.FloatTensor(self.features[time_index])\n",
    "\n",
    "    def _get_target(self, time_index: int):\n",
    "        if self.targets[time_index] is None:\n",
    "            return self.targets[time_index]\n",
    "        else:\n",
    "            if self.targets[time_index].dtype.kind == \"i\":\n",
    "                return torch.LongTensor(self.targets[time_index])\n",
    "            elif self.targets[time_index].dtype.kind == \"f\":\n",
    "                return torch.FloatTensor(self.targets[time_index])\n",
    "\n",
    "    def _get_additional_feature(self, time_index: int, feature_key: str):\n",
    "        feature = getattr(self, feature_key)[time_index]\n",
    "        if feature.dtype.kind == \"i\":\n",
    "            return torch.LongTensor(feature)\n",
    "        elif feature.dtype.kind == \"f\":\n",
    "            return torch.FloatTensor(feature)\n",
    "\n",
    "    def _get_additional_features(self, time_index: int):\n",
    "        additional_features = {\n",
    "            key: self._get_additional_feature(time_index, key)\n",
    "            for key in self.additional_feature_keys\n",
    "        }\n",
    "        return additional_features\n",
    "\n",
    "    def __getitem__(self, time_index: Union[int, slice]):\n",
    "        if isinstance(time_index, slice):\n",
    "            snapshot = StaticGraphTemporalSignal(\n",
    "                self.edge_index,\n",
    "                self.edge_weight,\n",
    "                self.features[time_index],\n",
    "                self.targets[time_index],\n",
    "                **{key: getattr(self, key)[time_index] for key in self.additional_feature_keys}\n",
    "            )\n",
    "        else:\n",
    "            x = self._get_features(time_index)\n",
    "            edge_index = self._get_edge_index()\n",
    "            edge_weight = self._get_edge_weight()\n",
    "            y = self._get_target(time_index)\n",
    "            additional_features = self._get_additional_features(time_index)\n",
    "\n",
    "            snapshot = Data(x=x, edge_index=edge_index, edge_attr=edge_weight,\n",
    "                            y=y, **additional_features)\n",
    "        return snapshot\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.t < len(self.features):\n",
    "            snapshot = self[self.t]\n",
    "            self.t = self.t + 1\n",
    "            return snapshot\n",
    "        else:\n",
    "            self.t = 0\n",
    "            raise StopIteration\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.t = 0\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Edge_Indices = Sequence[Union[np.ndarray, None]]\n",
    "Edge_Weights = Sequence[Union[np.ndarray, None]]\n",
    "Node_Features = Sequence[Union[np.ndarray, None]]\n",
    "Targets = Sequence[Union[np.ndarray, None]]\n",
    "Additional_Features = Sequence[np.ndarray]\n",
    "\n",
    "# Copied from PyG temporal rather than imported as the library has dependency issues\n",
    "# https://pytorch-geometric-temporal.readthedocs.io/en/latest/_modules/torch_geometric_temporal/signal/dynamic_graph_temporal_signal.html\n",
    "class DynamicGraphTemporalSignal(object):\n",
    "    r\"\"\"A data iterator object to contain a dynamic graph with a\n",
    "    changing edge set and weights . The feature set and node labels\n",
    "    (target) are also dynamic. The iterator returns a single discrete temporal\n",
    "    snapshot for a time period (e.g. day or week). This single snapshot is a\n",
    "    Pytorch Geometric Data object. Between two temporal snapshots the edges,\n",
    "    edge weights, target matrices and optionally passed attributes might change.\n",
    "\n",
    "    Args:\n",
    "        edge_indices (Sequence of Numpy arrays): Sequence of edge index tensors.\n",
    "        edge_weights (Sequence of Numpy arrays): Sequence of edge weight tensors.\n",
    "        features (Sequence of Numpy arrays): Sequence of node feature tensors.\n",
    "        targets (Sequence of Numpy arrays): Sequence of node label (target) tensors.\n",
    "        **kwargs (optional Sequence of Numpy arrays): Sequence of additional attributes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        edge_indices: Edge_Indices,\n",
    "        edge_weights: Edge_Weights,\n",
    "        features: Node_Features,\n",
    "        targets: Targets,\n",
    "        **kwargs: Additional_Features\n",
    "    ):\n",
    "        self.edge_indices = edge_indices\n",
    "        self.edge_weights = edge_weights\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        self.additional_feature_keys = []\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "            self.additional_feature_keys.append(key)\n",
    "        self._check_temporal_consistency()\n",
    "        self._set_snapshot_count()\n",
    "\n",
    "    def _check_temporal_consistency(self):\n",
    "        assert len(self.features) == len(\n",
    "            self.targets\n",
    "        ), \"Temporal dimension inconsistency.\"\n",
    "        assert len(self.edge_indices) == len(\n",
    "            self.edge_weights\n",
    "        ), \"Temporal dimension inconsistency.\"\n",
    "        assert len(self.features) == len(\n",
    "            self.edge_weights\n",
    "        ), \"Temporal dimension inconsistency.\"\n",
    "        for key in self.additional_feature_keys:\n",
    "            assert len(self.targets) == len(\n",
    "                getattr(self, key)\n",
    "            ), \"Temporal dimension inconsistency.\"\n",
    "\n",
    "    def _set_snapshot_count(self):\n",
    "        self.snapshot_count = len(self.features)\n",
    "\n",
    "    def _get_edge_index(self, time_index: int):\n",
    "        if self.edge_indices[time_index] is None:\n",
    "            return self.edge_indices[time_index]\n",
    "        else:\n",
    "            return torch.LongTensor(self.edge_indices[time_index])\n",
    "\n",
    "    def _get_edge_weight(self, time_index: int):\n",
    "        if self.edge_weights[time_index] is None:\n",
    "            return self.edge_weights[time_index]\n",
    "        else:\n",
    "            return torch.FloatTensor(self.edge_weights[time_index])\n",
    "\n",
    "    def _get_features(self, time_index: int):\n",
    "        if self.features[time_index] is None:\n",
    "            return self.features[time_index]\n",
    "        else:\n",
    "            return torch.FloatTensor(self.features[time_index])\n",
    "\n",
    "    def _get_target(self, time_index: int):\n",
    "        if self.targets[time_index] is None:\n",
    "            return self.targets[time_index]\n",
    "        else:\n",
    "            if self.targets[time_index].dtype.kind == \"i\":\n",
    "                return torch.LongTensor(self.targets[time_index])\n",
    "            elif self.targets[time_index].dtype.kind == \"f\":\n",
    "                return torch.FloatTensor(self.targets[time_index])\n",
    "\n",
    "    def _get_additional_feature(self, time_index: int, feature_key: str):\n",
    "        feature = getattr(self, feature_key)[time_index]\n",
    "        if feature.dtype.kind == \"i\":\n",
    "            return torch.LongTensor(feature)\n",
    "        elif feature.dtype.kind == \"f\":\n",
    "            return torch.FloatTensor(feature)\n",
    "\n",
    "    def _get_additional_features(self, time_index: int):\n",
    "        additional_features = {\n",
    "            key: self._get_additional_feature(time_index, key)\n",
    "            for key in self.additional_feature_keys\n",
    "        }\n",
    "        return additional_features\n",
    "\n",
    "    def __getitem__(self, time_index: Union[int, slice]):\n",
    "        if isinstance(time_index, slice):\n",
    "            snapshot = DynamicGraphTemporalSignal(\n",
    "                self.edge_indices[time_index],\n",
    "                self.edge_weights[time_index],\n",
    "                self.features[time_index],\n",
    "                self.targets[time_index],\n",
    "                **{key: getattr(self, key)[time_index] for key in self.additional_feature_keys}\n",
    "            )\n",
    "        else:\n",
    "            x = self._get_features(time_index)\n",
    "            edge_index = self._get_edge_index(time_index)\n",
    "            edge_weight = self._get_edge_weight(time_index)\n",
    "            y = self._get_target(time_index)\n",
    "            additional_features = self._get_additional_features(time_index)\n",
    "\n",
    "            snapshot = Data(x=x, edge_index=edge_index, edge_attr=edge_weight,\n",
    "                            y=y, **additional_features)\n",
    "        return snapshot\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.t < len(self.features):\n",
    "            snapshot = self[self.t]\n",
    "            self.t = self.t + 1\n",
    "            return snapshot\n",
    "        else:\n",
    "            self.t = 0\n",
    "            raise StopIteration\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.t = 0\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from typing import Union\n",
    "import glob\n",
    "from natsort import natsorted\n",
    "import random\n",
    "\n",
    "# Fix random seed for ease of reproduction\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "class SP500CorrelationsDatasetLoader(object):\n",
    "    def __init__(self, corr_name, corr_scope):\n",
    "        self._read_csv(corr_name, corr_scope)\n",
    "\n",
    "    def _load_global_corr(self, corr_name):\n",
    "        return np.loadtxt(f'{corr_name}/global_corr.csv', delimiter=',')\n",
    "\n",
    "    def _load_local_corrs(self, corr_name):\n",
    "        _correlation_matrices = []\n",
    "        corr_files = natsorted(glob.glob(f'{corr_name}/local_corr_*.csv'))\n",
    "        for corr_file in corr_files:\n",
    "            matrix = np.loadtxt(corr_file, delimiter=',')\n",
    "            _correlation_matrices.append(matrix)\n",
    "        return _correlation_matrices\n",
    "\n",
    "    def _read_csv(self, corr_name, corr_scope):\n",
    "        match corr_scope:\n",
    "            case 'global':\n",
    "                self._correlation_matrices = [self._load_global_corr(corr_name)]\n",
    "            case 'local':\n",
    "                self._correlation_matrices = self._load_local_corrs(corr_name)\n",
    "            case 'dual':\n",
    "                global_corr = self._load_global_corr(corr_name)\n",
    "                self._correlation_matrices = [np.stack((global_corr, local_corr), axis=-1) for local_corr in self._load_local_corrs(corr_name)]\n",
    "            case None:\n",
    "                # None uses identity matrix as correlation\n",
    "                # Infer dimension from a global correlation matrix\n",
    "                global_corr = self._load_global_corr('pcc')\n",
    "                self._correlation_matrices = [np.eye(global_corr.shape[0], global_corr.shape[1])]\n",
    "        \n",
    "        if corr_name == 'mi':\n",
    "            # Normalize MI to [0, 1]\n",
    "            max_mi = 0\n",
    "            for matrix in self._correlation_matrices:\n",
    "                max_mi = max(np.max(matrix), max_mi)\n",
    "                # MI shouldn't be negative\n",
    "                matrix[matrix < 0] = 0\n",
    "            for matrix in self._correlation_matrices:\n",
    "                matrix = matrix / max_mi\n",
    "        \n",
    "        df = pd.read_csv('s&p500.csv')\n",
    "        df = df.set_index('Date')\n",
    "        data = torch.from_numpy(df.to_numpy()).to(torch.float32)\n",
    "\n",
    "        # Round data size to nearest multiple of batch_size\n",
    "        self.days_in_quarter = 64\n",
    "        num_quarters = data.size(0) // self.days_in_quarter\n",
    "        num_days = num_quarters * self.days_in_quarter\n",
    "        data = data[:num_days]\n",
    "        \n",
    "        # z-score normalization with training data following GERU\n",
    "        train_days = int(0.8 * num_quarters) * self.days_in_quarter\n",
    "        data = (data - data[:train_days].mean(dim=0)) / data[:train_days].std(dim=0)\n",
    "        data = data.numpy()\n",
    "\n",
    "        data = data[..., np.newaxis]\n",
    "\n",
    "        assert(not np.any(np.isnan(data)))\n",
    "        self._dataset = data\n",
    "\n",
    "    def _get_edges(self, times, overlap):\n",
    "        def helper(corr_index):\n",
    "            return np.array(np.ones(self._correlation_matrices[corr_index].shape[:2]).nonzero())\n",
    "        \n",
    "        if len(self._correlation_matrices) == 1:\n",
    "            _edges = helper(0)\n",
    "        else:\n",
    "            _edges = []\n",
    "            for time in range(0, self._dataset.shape[0] - self.batch_size, overlap):\n",
    "                if not time in times:\n",
    "                    continue\n",
    "                corr_index = max(0, time // self.days_in_quarter - 1)\n",
    "                _edges.append(\n",
    "                    helper(corr_index)\n",
    "                )\n",
    "        return _edges\n",
    "\n",
    "    def _get_edge_weights(self, times, overlap):\n",
    "        def helper(corr_index):\n",
    "            w = self._correlation_matrices[corr_index]\n",
    "            # Flatten the first two dimensions\n",
    "            return w.reshape((w.shape[0] * w.shape[1],) + w.shape[2:])\n",
    "\n",
    "        if len(self._correlation_matrices) == 1:\n",
    "            _edge_weights = helper(0)\n",
    "        else:\n",
    "            _edge_weights = []\n",
    "            for time in range(0, self._dataset.shape[0] - self.batch_size, overlap):\n",
    "                if not time in times:\n",
    "                    continue\n",
    "                corr_index = max(0, time // self.days_in_quarter - 1)\n",
    "                _edge_weights.append(\n",
    "                    helper(corr_index)\n",
    "                )\n",
    "        return _edge_weights\n",
    "\n",
    "    def _get_targets_and_features(self, times, overlap, predict_all):\n",
    "        features = [\n",
    "            self._dataset[i : i + self.batch_size, :]\n",
    "            for i in range(0, self._dataset.shape[0] - self.batch_size, overlap)\n",
    "            if i in times\n",
    "        ]\n",
    "        # predict next-day stock prices\n",
    "        targets = [\n",
    "            (self._dataset[i+1 : i + self.batch_size+1, :, 0]).T if predict_all else (self._dataset[i + self.batch_size, :, 0]).T\n",
    "            for i in range(0, self._dataset.shape[0] - self.batch_size, overlap)\n",
    "            if i in times\n",
    "        ]\n",
    "        return features, targets\n",
    "\n",
    "    def get_dataset(self, batch_size, split) -> Union[StaticGraphTemporalSignal, DynamicGraphTemporalSignal]:\n",
    "        \"\"\"Returning the data iterator.\n",
    "        \"\"\"\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        total_times = list(range(0, self._dataset.shape[0] - self.batch_size, self.batch_size))\n",
    "\n",
    "        if split == 'train':\n",
    "            times = list(range(total_times[int(len(total_times) * 0)], total_times[int(len(total_times) * 0.8)]))\n",
    "            overlap = self.batch_size\n",
    "            predict_all = True\n",
    "        elif split == 'val':\n",
    "            times = list(range(total_times[int(len(total_times) * 0.8)], total_times[int(len(total_times) * 0.9)]))\n",
    "            overlap = 1\n",
    "            predict_all = False\n",
    "        elif split == 'test':\n",
    "            times = list(range(total_times[int(len(total_times) * 0.9)], total_times[-1] + self.batch_size))\n",
    "            overlap = 1\n",
    "            predict_all = False\n",
    "        else:\n",
    "            raise ValueError(f'Invalid split name: {split}')\n",
    "\n",
    "        _edges = self._get_edges(times, overlap)\n",
    "        _edge_weights = self._get_edge_weights(times, overlap)\n",
    "        features, targets = self._get_targets_and_features(times, overlap, predict_all)\n",
    "        dataset = (DynamicGraphTemporalSignal if type(_edges) == list else StaticGraphTemporalSignal)(\n",
    "            _edges, _edge_weights, features, targets\n",
    "        )\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(corr_name, corr_scope):\n",
    "    loader = SP500CorrelationsDatasetLoader(corr_name=corr_name, corr_scope=corr_scope)\n",
    "\n",
    "    lag_size = 64\n",
    "    train_dataset = loader.get_dataset(batch_size=lag_size * 2, split='train')\n",
    "    val_dataset = loader.get_dataset(batch_size=lag_size, split='val')\n",
    "    test_dataset = loader.get_dataset(batch_size=lag_size, split='test')\n",
    "\n",
    "    train_samples = list(train_dataset)\n",
    "    val_samples = list(val_dataset)\n",
    "    test_samples = list(test_dataset)\n",
    "\n",
    "    return {\n",
    "        'train_samples': train_samples,\n",
    "        'val_samples': val_samples,\n",
    "        'test_samples': test_samples,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differential Graph Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from reference implementation of Differential Transformer, included an optional A input to MultiheadDiffAttn.forward()\n",
    "# https://github.com/microsoft/unilm/blob/master/Diff-Transformer/multihead_diffattn.py\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, dim: int, eps: float = 1e-6, elementwise_affine=True):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.eps = eps\n",
    "        self.elementwise_affine = elementwise_affine\n",
    "        if self.elementwise_affine:\n",
    "            self.weight = nn.Parameter(torch.ones(dim))\n",
    "        else:\n",
    "            self.register_parameter('weight', None)\n",
    "\n",
    "    def _norm(self, x):\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self._norm(x.float()).type_as(x)\n",
    "        if self.weight is not None:\n",
    "            output = output * self.weight\n",
    "        return output\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f'dim={self.dim}, eps={self.eps}, elementwise_affine={self.elementwise_affine}'\n",
    "\n",
    "\n",
    "def init_method(tensor, **kwargs):\n",
    "    nn.init.kaiming_uniform_(tensor, a=math.sqrt(5))\n",
    "\n",
    "def repeat_kv(x: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
    "    \"\"\"torch.repeat_interleave(x, dim=1, repeats=n_rep)\"\"\"\n",
    "    bs, n_kv_heads, slen, head_dim = x.shape\n",
    "    if n_rep == 1:\n",
    "        return x\n",
    "    return (\n",
    "        x[:, :, None, :, :]\n",
    "        .expand(bs, n_kv_heads, n_rep, slen, head_dim)\n",
    "        .reshape(bs, n_kv_heads * n_rep, slen, head_dim)\n",
    "    )\n",
    "\n",
    "def lambda_init_fn(depth):\n",
    "    return 0.8 - 0.6 * math.exp(-0.3 * depth)\n",
    "\n",
    "\n",
    "class MultiheadDiffAttn(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embed_dim,\n",
    "        depth,\n",
    "        num_heads,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        # num_heads set to half of Transformer's #heads\n",
    "        self.num_heads = num_heads\n",
    "        self.num_kv_heads = num_heads\n",
    "        self.n_rep = self.num_heads // self.num_kv_heads\n",
    "        \n",
    "        self.head_dim = embed_dim // num_heads // 2\n",
    "        self.scaling = self.head_dim ** -0.5\n",
    "        \n",
    "        self.q_proj = nn.Linear(embed_dim, embed_dim, bias=False)\n",
    "        self.k_proj = nn.Linear(embed_dim, embed_dim // self.n_rep, bias=False)\n",
    "        self.v_proj = nn.Linear(embed_dim, embed_dim // self.n_rep, bias=False)\n",
    "\n",
    "        self.lambda_init = lambda_init_fn(depth)\n",
    "        self.lambda_q1 = nn.Parameter(torch.zeros(self.head_dim, dtype=torch.float32).normal_(mean=0,std=0.1))\n",
    "        self.lambda_k1 = nn.Parameter(torch.zeros(self.head_dim, dtype=torch.float32).normal_(mean=0,std=0.1))\n",
    "        self.lambda_q2 = nn.Parameter(torch.zeros(self.head_dim, dtype=torch.float32).normal_(mean=0,std=0.1))\n",
    "        self.lambda_k2 = nn.Parameter(torch.zeros(self.head_dim, dtype=torch.float32).normal_(mean=0,std=0.1))\n",
    "\n",
    "        self.subln = RMSNorm(2 * self.head_dim, eps=1e-5, elementwise_affine=True)\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        x,\n",
    "        A=None,\n",
    "        attn_mask=None,\n",
    "    ):\n",
    "        bsz, tgt_len, embed_dim = x.size()\n",
    "        src_len = tgt_len\n",
    "\n",
    "        q = self.q_proj(x)\n",
    "        k = self.k_proj(x)\n",
    "        v = self.v_proj(x)\n",
    "\n",
    "        q = q.view(bsz, tgt_len, 2 * self.num_heads, self.head_dim)\n",
    "        k = k.view(bsz, src_len, 2 * self.num_kv_heads, self.head_dim)\n",
    "        v = v.view(bsz, src_len, self.num_kv_heads, 2 * self.head_dim)\n",
    "\n",
    "        q = q.transpose(1, 2)\n",
    "        k = repeat_kv(k.transpose(1, 2), self.n_rep)\n",
    "        v = repeat_kv(v.transpose(1, 2), self.n_rep)\n",
    "        q *= self.scaling\n",
    "        attn_weights = torch.matmul(q, k.transpose(-1, -2))\n",
    "        attn_weights = torch.nan_to_num(attn_weights)\n",
    "        if attn_mask is not None:\n",
    "            attn_weights += attn_mask\n",
    "        attn_weights = F.softmax(attn_weights, dim=-1, dtype=torch.float32).type_as(\n",
    "            attn_weights\n",
    "        )\n",
    "\n",
    "        lambda_1 = torch.exp(torch.sum(self.lambda_q1 * self.lambda_k1, dim=-1).float()).type_as(q)\n",
    "        lambda_2 = torch.exp(torch.sum(self.lambda_q2 * self.lambda_k2, dim=-1).float()).type_as(q)\n",
    "        lambda_full = lambda_1 - lambda_2 + self.lambda_init\n",
    "        attn_weights = attn_weights.view(bsz, self.num_heads, 2, tgt_len, src_len)\n",
    "        attn_weights = attn_weights[:, :, 0] * (1 if A is None else A) - lambda_full * attn_weights[:, :, 1]\n",
    "        \n",
    "        attn = torch.matmul(attn_weights, v)\n",
    "        attn = self.subln(attn)\n",
    "        attn = attn * (1 - self.lambda_init)\n",
    "        attn = attn.transpose(1, 2).reshape(bsz, tgt_len, self.num_heads * 2 * self.head_dim)\n",
    "        return (attn, attn_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, hidden_size, expand_ratio, dropout):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.linear = nn.Linear(hidden_size, hidden_size * expand_ratio)\n",
    "        self.linear2 = nn.Linear(hidden_size * expand_ratio, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, expand_ratio, dropout):\n",
    "        super().__init__()\n",
    "        self.mha = MultiheadDiffAttn(embed_dim=d_model, num_heads=num_heads, depth=0)\n",
    "        self.ln2 = nn.LayerNorm(d_model)\n",
    "        self.ffn = FeedForward(hidden_size=d_model, expand_ratio=expand_ratio, dropout=dropout)\n",
    "\n",
    "    def forward(self, x, A=None, attn_mask=None, need_weights=False):\n",
    "        x1, attn_weights = self.mha(x, A, attn_mask=attn_mask)\n",
    "        x = self.ln2(self.ffn(x1) + x1)\n",
    "        if need_weights:\n",
    "            return (x, attn_weights)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "\n",
    "class DGT(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=32, num_heads=2, num_layers=2, expand_ratio=1, dropout=0.1, T = 128, N=472, use_spatial=True):\n",
    "        super().__init__()\n",
    "        self.T = T\n",
    "        self.N = N\n",
    "        self.d_model = out_channels\n",
    "        self.num_heads = num_heads\n",
    "        self.num_layers = num_layers\n",
    "        self.input_proj = nn.Linear(in_channels, out_channels)\n",
    "        self.time_embedding = nn.Embedding(T, out_channels)\n",
    "        self.stock_embedding = nn.Embedding(N, out_channels)\n",
    "        self.use_spatial = use_spatial\n",
    "        if use_spatial:\n",
    "            self.spatial_attns = nn.ModuleList([Attention(out_channels, num_heads, expand_ratio, dropout) for _ in range(num_layers)])\n",
    "        self.temporal_attns = nn.ModuleList([Attention(out_channels, num_heads, expand_ratio, dropout) for _ in range(num_layers)])\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_weight, need_weights=False):\n",
    "        N, T, D = x.size()\n",
    "        assert(D == 1)\n",
    "        assert(T <= self.T and N == self.N)\n",
    "\n",
    "        x = x.reshape(T, N, D)\n",
    "        x = self.input_proj(x)\n",
    "        stock_embs = self.stock_embedding(torch.arange(N).unsqueeze(0).expand(T, N).to(x.device))\n",
    "        x += stock_embs\n",
    "        time_embs = self.time_embedding(torch.arange(T).unsqueeze(0).expand(N, T).to(x.device))\n",
    "        x += time_embs.view(T, N, self.d_model)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = x.view(N, T, self.d_model)\n",
    "            temporal_causal_mask = torch.triu(\n",
    "                torch.zeros([T, T])\n",
    "                    .float()\n",
    "                    .fill_(float(\"-inf\")),\n",
    "                    1,\n",
    "                ).expand(N, self.num_heads*2, T, T).to(x.device)\n",
    "            x = self.temporal_attns[i](x, attn_mask=temporal_causal_mask, need_weights=need_weights) + x\n",
    "\n",
    "            if self.use_spatial:\n",
    "                x = x.view(T, N, self.d_model)\n",
    "                A = to_dense_adj(edge_index, edge_attr=edge_weight)\n",
    "                # Encountered more than one adjacency matrices, e.g. dual correlations\n",
    "                if len(A.size()) == 4:\n",
    "                    A = A.reshape(A.size(-1), A.size(1), A.size(2))\n",
    "                x = self.spatial_attns[i](x, A, need_weights=need_weights) + x\n",
    "                x = x.view(N, T, self.d_model)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(torch.nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, num_layers: int):\n",
    "        super(GRU, self).__init__()\n",
    "        self.rnn = nn.GRU(input_size=in_channels, hidden_size=out_channels, num_layers=num_layers, batch_first=True)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.FloatTensor,\n",
    "        edge_index: torch.LongTensor,\n",
    "        edge_weight: torch.FloatTensor = None,\n",
    "    ) -> torch.FloatTensor:\n",
    "        outputs, _ = self.rnn(x)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Driver(torch.nn.Module):\n",
    "    def __init__(self, gnn, corr_name, corr_scope, node_features, hidden_size=32, **kwargs):\n",
    "        super(Driver, self).__init__()\n",
    "        self.recurrent = gnn(in_channels=node_features, out_channels=hidden_size, **kwargs)\n",
    "        self.linear = torch.nn.Linear(hidden_size, 1)\n",
    "        self.corr_name = corr_name\n",
    "        self.corr_scope = corr_scope\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight, hidden=None):\n",
    "        device = self.model_device()\n",
    "        if hidden is None:\n",
    "            outputs = self.recurrent(x.to(device), edge_index.to(device), edge_weight.to(device))\n",
    "        else:\n",
    "            outputs = self.recurrent(x.to(device), edge_index.to(device), edge_weight.to(device), hidden)\n",
    "        return self.linear(F.relu(outputs)), outputs\n",
    "\n",
    "    def model_name(self):\n",
    "        arch = self.model_arch()\n",
    "        if arch == 'GRU':\n",
    "            return f'{arch}'\n",
    "        elif arch == 'DGT':\n",
    "            name = f'{arch}{\"\" if self.recurrent.use_spatial else \"_no_spatial\"}'\n",
    "            if self.corr_scope is not None:\n",
    "                name += f'_{self.corr_name}_{self.corr_scope}'\n",
    "            return name\n",
    "\n",
    "    def model_arch(self):\n",
    "        return self.recurrent.__class__.__name__\n",
    "\n",
    "    def model_device(self):\n",
    "        return torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def rmse(y_hat, y):\n",
    "    return math.sqrt(F.mse_loss(y_hat, y).item())\n",
    "\n",
    "def mae(y_hat, y):\n",
    "    return F.l1_loss(y_hat, y).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "def infer(model, snapshot):\n",
    "    X = snapshot.x\n",
    "    batch_y_hats, _ = model(X.transpose(0, 1), snapshot.edge_index, snapshot.edge_attr)\n",
    "    return batch_y_hats[:, -1]\n",
    "\n",
    "def eval(epoch, model, eval_dataset, eval_name):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_hats = list(map(lambda snapshot: infer(model, snapshot), eval_dataset))\n",
    "        ys = [snapshot.y for snapshot in eval_dataset]\n",
    "        y_hats, ys = torch.cat(y_hats, dim=0).squeeze().to(model.model_device()), torch.cat(ys, dim=0).to(model.model_device())\n",
    "        eval_rmse = rmse(y_hats, ys)\n",
    "        eval_mae = mae(y_hats, ys)\n",
    "        wandb.log({\"epoch\": epoch,\n",
    "                f\"{eval_name}/rmse\": eval_rmse,\n",
    "                f\"{eval_name}/mae\": eval_mae })\n",
    "        print(f'{model.model_name()} epoch {epoch}, {eval_name}/rmse: {eval_rmse}, {eval_name}/mae: {eval_mae}')\n",
    "        return (eval_rmse, eval_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(gnn, use_spatial, corr_name, corr_scope, load_weights=False):\n",
    "    node_features = 1\n",
    "    if gnn == DGT:\n",
    "        model = Driver(gnn, corr_name, corr_scope, node_features, num_heads=2, use_spatial=use_spatial)\n",
    "    elif gnn == GRU:\n",
    "        # GRU does not support any correlation\n",
    "        if corr_name != None or corr_scope != None:\n",
    "            return None\n",
    "        model = Driver(gnn, None, None, node_features, num_layers=2)\n",
    "    if load_weights:\n",
    "        model.load_state_dict(torch.load(f'models/{model.model_name()}.pth', weights_only=True))\n",
    "    return model.to(model.model_device())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkevinxli\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Volumes/crucialx9/classes/fall2024/cs224w/stock/wandb/run-20241210_135441-mmprekip</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kevinxli/cs224w-stock-market-prediction/runs/mmprekip' target=\"_blank\">DGT_no_spatial</a></strong> to <a href='https://wandb.ai/kevinxli/cs224w-stock-market-prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kevinxli/cs224w-stock-market-prediction' target=\"_blank\">https://wandb.ai/kevinxli/cs224w-stock-market-prediction</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kevinxli/cs224w-stock-market-prediction/runs/mmprekip' target=\"_blank\">https://wandb.ai/kevinxli/cs224w-stock-market-prediction/runs/mmprekip</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DGT_no_spatial epoch 0, val/rmse: 0.7571670300231416, val/mae: 0.4430655539035797\n",
      "DGT_no_spatial epoch 10, val/rmse: 0.3678467696178314, val/mae: 0.14687785506248474\n",
      "DGT_no_spatial epoch 20, val/rmse: 0.3356530848532256, val/mae: 0.12802942097187042\n",
      "DGT_no_spatial epoch 30, val/rmse: 0.31537561573205836, val/mae: 0.12420626729726791\n",
      "DGT_no_spatial epoch 40, val/rmse: 0.2795419218223576, val/mae: 0.13097326457500458\n",
      "DGT_no_spatial epoch 50, val/rmse: 0.27308325300069014, val/mae: 0.09586146473884583\n",
      "DGT_no_spatial epoch 60, val/rmse: 0.27379323435046093, val/mae: 0.09436680376529694\n",
      "DGT_no_spatial epoch 70, val/rmse: 0.26846604705025345, val/mae: 0.08797424286603928\n",
      "DGT_no_spatial epoch 80, val/rmse: 0.26512103798373005, val/mae: 0.08422688394784927\n",
      "DGT_no_spatial epoch 90, val/rmse: 0.266936737754339, val/mae: 0.08740387856960297\n",
      "DGT_no_spatial epoch 99, val/rmse: 0.2598896160923765, val/mae: 0.08704680949449539\n",
      "DGT_no_spatial epoch 100, test/rmse: 1.2119966858418794, test/mae: 0.20467372238636017\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import os\n",
    "\n",
    "def train(gnn, use_spatial, corr_name, corr_scope, train_samples, val_samples, num_epochs):\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "\n",
    "    model = get_model(gnn, use_spatial, corr_name, corr_scope, load_weights=False)\n",
    "\n",
    "    lr = 1e-2\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    track_with_wandb = True\n",
    "    best_val_rmse = float('inf')\n",
    "    eval_per_epoch = 10\n",
    "\n",
    "    if track_with_wandb:\n",
    "        wandb.init(project=\"cs224w-stock-market-prediction\",\n",
    "                   name=f'{model.model_name()}',\n",
    "                   config={\n",
    "                       \"corr_name\": corr_name,\n",
    "                       \"corr_scope\": corr_scope,\n",
    "                       \"learning_rate\": lr,\n",
    "                       \"epochs\": num_epochs,\n",
    "                       \"architecture\": gnn.__name__,\n",
    "                       \"use_spatial\": use_spatial,\n",
    "                   })\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for step, snapshot in enumerate(train_samples):\n",
    "            X = snapshot.x\n",
    "            y_hats, _ = model(X.transpose(0, 1), snapshot.edge_index, snapshot.edge_attr, hidden=None)\n",
    "            loss = F.mse_loss(y_hats.squeeze(), snapshot.y.to(model.model_device()))\n",
    "            train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            if track_with_wandb:\n",
    "                wandb.log({\"epoch\": epoch,\n",
    "                        \"step\": step,\n",
    "                            \"train/loss\": loss.item() })\n",
    "        train_loss /= len(train_samples)\n",
    "\n",
    "        if track_with_wandb and (epoch % eval_per_epoch == 0 or epoch == num_epochs - 1):\n",
    "            val_rmse, val_mae = eval(epoch, model, val_samples, 'val')\n",
    "            if val_rmse < best_val_rmse:\n",
    "                best_val_rmse = val_rmse\n",
    "                torch.save(model.state_dict(), f'models/{model.model_name()}.pth')\n",
    "\n",
    "model_configs = [(DGT, False, None, None),\n",
    "                #  (DGT, True, 'mi', 'global'),\n",
    "                #  (DGT, True, 'mi', 'local'),\n",
    "                #  (DGT, True, 'mi', 'dual'),\n",
    "                #  (DGT, True, 'pcc', 'global'),\n",
    "                #  (DGT, True, 'pcc', 'local'),\n",
    "                #  (DGT, True, 'pcc', 'dual'),\n",
    "                 ]\n",
    "num_epochs = 100\n",
    "for gnn, use_spatial, corr_name, corr_scope in model_configs:\n",
    "    dataset = get_dataset(corr_name, corr_scope)\n",
    "    train(gnn, use_spatial, corr_name, corr_scope, dataset['train_samples'], dataset['val_samples'], num_epochs)\n",
    "    # Test\n",
    "    best_model = get_model(gnn, use_spatial, corr_name, corr_scope, load_weights=True)\n",
    "    eval(num_epochs, best_model, dataset['test_samples'], 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_names = \"A,AAL,AAPL,ABBV,ABT,ACGL,ACN,ADBE,ADI,ADM,ADP,ADSK,AEE,AEP,AES,AFL,AIG,AIZ,AJG,AKAM,ALB,ALGN,ALL,ALLE,AMAT,AMCR,AMD,AME,AMGN,AMP,AMT,AMZN,ANET,ANSS,AON,AOS,APA,APD,APH,APTV,ARE,ATO,AVB,AVGO,AVY,AWK,AXON,AXP,AZO,BA,BAC,BALL,BAX,BBWI,BBY,BDX,BEN,BF-B,BG,BIIB,BIO,BK,BKNG,BKR,BLDR,BLK,BMY,BR,BRK-B,BRO,BSX,BWA,BX,BXP,C,CAG,CAH,CAT,CB,CBOE,CBRE,CCI,CCL,CDNS,CDW,CE,CF,CFG,CHD,CHRW,CHTR,CI,CINF,CL,CLX,CMCSA,CME,CMG,CMI,CMS,CNC,CNP,COF,COO,COP,COR,COST,CPAY,CPB,CPRT,CPT,CRL,CRM,CSCO,CSGP,CSX,CTAS,CTLT,CTRA,CTSH,CVS,CVX,CZR,D,DAL,DD,DE,DECK,DFS,DG,DGX,DHI,DHR,DIS,DLR,DLTR,DOC,DOV,DPZ,DRI,DTE,DUK,DVA,DVN,DXCM,EA,EBAY,ECL,ED,EFX,EG,EIX,EL,ELV,EMN,EMR,ENPH,EOG,EPAM,EQIX,EQR,EQT,ES,ESS,ETN,ETR,EVRG,EW,EXC,EXPD,EXPE,EXR,F,FANG,FAST,FCX,FDS,FDX,FE,FFIV,FI,FICO,FIS,FITB,FMC,FRT,FSLR,FTNT,GD,GE,GEN,GILD,GIS,GL,GLW,GM,GNRC,GOOG,GOOGL,GPC,GPN,GRMN,GS,GWW,HAL,HAS,HBAN,HCA,HD,HES,HIG,HII,HLT,HOLX,HON,HPQ,HRL,HSIC,HST,HSY,HUBB,HUM,IBM,ICE,IDXX,IEX,IFF,INCY,INTC,INTU,IP,IPG,IQV,IRM,ISRG,IT,ITW,IVZ,J,JBHT,JBL,JCI,JKHY,JNJ,JNPR,JPM,K,KDP,KEY,KEYS,KIM,KKR,KLAC,KMB,KMI,KMX,KO,KR,L,LDOS,LEN,LH,LHX,LIN,LKQ,LLY,LMT,LNT,LOW,LRCX,LULU,LUV,LVS,LYB,LYV,MA,MAA,MAR,MAS,MCD,MCHP,MCK,MCO,MDLZ,MDT,MET,META,MGM,MHK,MKC,MKTX,MLM,MMC,MMM,MNST,MO,MOH,MOS,MPC,MPWR,MRK,MRO,MS,MSCI,MSFT,MSI,MTB,MTCH,MTD,MU,NCLH,NDAQ,NDSN,NEE,NEM,NFLX,NI,NKE,NOC,NOW,NRG,NSC,NTAP,NTRS,NUE,NVDA,NVR,NWS,NWSA,NXPI,O,ODFL,OKE,OMC,ON,ORCL,ORLY,OXY,PANW,PARA,PAYC,PAYX,PCAR,PCG,PEG,PEP,PFE,PFG,PG,PGR,PH,PHM,PKG,PLD,PM,PNC,PNR,PNW,PODD,POOL,PPG,PPL,PRU,PSA,PSX,PTC,PWR,QCOM,RCL,REG,REGN,RF,RJF,RL,RMD,ROK,ROL,ROP,ROST,RSG,RTX,RVTY,SBAC,SBUX,SCHW,SHW,SJM,SLB,SMCI,SNA,SNPS,SO,SPG,SPGI,SRE,STE,STLD,STT,STX,STZ,SWK,SWKS,SYF,SYK,SYY,T,TAP,TDG,TDY,TECH,TEL,TER,TFC,TFX,TGT,TJX,TMO,TMUS,TPR,TRGP,TRMB,TROW,TRV,TSCO,TSLA,TSN,TT,TTWO,TXN,TXT,TYL,UAL,UDR,UHS,ULTA,UNH,UNP,UPS,URI,USB,V,VLO,VMC,VRSK,VRSN,VRTX,VTR,VTRS,VZ,WAB,WAT,WBA,WBD,WDC,WEC,WELL,WFC,WM,WMB,WMT,WRB,WST,WTW,WY,WYNN,XEL,XOM,XYL,YUM,ZBH,ZBRA,ZTS\"\n",
    "stock_names = stock_names.split(',')\n",
    "stock_lookup = {name: i for i, name in enumerate(stock_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_model() missing 1 required positional argument: 'corr_scope'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 50\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m preds, targets\n\u001b[1;32m     49\u001b[0m preds \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 50\u001b[0m preds, targets \u001b[38;5;241m=\u001b[39m \u001b[43mplot_regression\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpcc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mglobal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDGT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m                            \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpcc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlocal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDGT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m                           \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpcc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdual\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDGT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                           \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGlobal Pearson with DGT\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLocal Pearson with DGT\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDual Pearson with DGT\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstock_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNVDA\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfig_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msp500_regression_NVDA.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m preds, targets \u001b[38;5;241m=\u001b[39m plot_regression([(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpcc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglobal\u001b[39m\u001b[38;5;124m'\u001b[39m, DGT),\n\u001b[1;32m     55\u001b[0m                             (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpcc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal\u001b[39m\u001b[38;5;124m'\u001b[39m, DGT),\n\u001b[1;32m     56\u001b[0m                            (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpcc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdual\u001b[39m\u001b[38;5;124m'\u001b[39m, DGT)],\n\u001b[1;32m     57\u001b[0m                            [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGlobal Pearson with DGT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLocal Pearson with DGT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDual Pearson with DGT\u001b[39m\u001b[38;5;124m'\u001b[39m], stock_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJNJ\u001b[39m\u001b[38;5;124m'\u001b[39m, fig_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msp500_regression_JNJ.png\u001b[39m\u001b[38;5;124m'\u001b[39m, preds\u001b[38;5;241m=\u001b[39mpreds)\n",
      "Cell \u001b[0;32mIn[14], line 19\u001b[0m, in \u001b[0;36mplot_regression\u001b[0;34m(configs, labels, fig_name, stock_name, preds)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (corr_name, corr_scope, gnn), label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(configs, labels):\n\u001b[1;32m     18\u001b[0m     eval_dataset \u001b[38;5;241m=\u001b[39m get_dataset(corr_name, corr_scope)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_samples\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 19\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorr_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorr_scope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: get_model() missing 1 required positional argument: 'corr_scope'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from cycler import cycler\n",
    "\n",
    "# Plot regression results on test set\n",
    "def plot_regression(configs, labels, fig_name, stock_name, preds): # 235 is for Nvidia\n",
    "    stock_index = stock_lookup[stock_name]\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    colors = [(0.650, 0.120, 0.240, 0.6),  # red\n",
    "              (0.122, 0.467, 0.706, 0.6), # blue\n",
    "              (1.000, 0.498, 0.055), # orange\n",
    "              (0.580, 0.403, 0.741, 0.6), # purple\n",
    "              ]\n",
    "    plt.rc('axes', prop_cycle=cycler('color', colors))\n",
    "\n",
    "    for (corr_name, corr_scope, gnn), label in zip(configs, labels):\n",
    "        eval_dataset = get_dataset(corr_name, corr_scope)['test_samples']\n",
    "        model = get_model(gnn, corr_name, corr_scope, load_weights=True)\n",
    "        if model is None:\n",
    "            continue\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            if label not in preds:\n",
    "                y_hats = list(map(lambda snapshot: infer(model, snapshot).squeeze().cpu(), eval_dataset))\n",
    "                preds[label] = y_hats\n",
    "            else:\n",
    "                y_hats = preds[label]\n",
    "            ys = [snapshot.y.cpu() for snapshot in eval_dataset]\n",
    "            targets = ys\n",
    "            assert(len(y_hats) == len(ys))\n",
    "            x = np.array(range(len(ys)))\n",
    "            print(f'{label} Overall MAE: {mae(torch.stack(y_hats, dim=1), torch.stack(ys, dim=1))}')\n",
    "            ys = np.array([y[stock_index] for y in ys])\n",
    "            y_hats = np.array([y_hat[stock_index] for y_hat in y_hats])\n",
    "            print(f'{label} Stock {stock_index} MAE: {mae(torch.tensor(y_hats), torch.tensor(ys))}')\n",
    "            plt.plot(x, y_hats, label=label, linewidth=1)\n",
    "\n",
    "    plt.plot(x, ys, label=\"Real\", color='green')\n",
    "    plt.legend(fontsize=14)\n",
    "    plt.title(f'Predicted vs Real {stock_name} Stock Price', fontsize=20)\n",
    "    plt.xlabel('Days', fontsize=16)\n",
    "    plt.ylabel('Normalized Price', fontsize=16)\n",
    "    plt.tick_params(axis='x', labelsize=16)\n",
    "    plt.tick_params(axis='y', labelsize=16)\n",
    "    plt.savefig(fig_name)\n",
    "    return preds, targets\n",
    "\n",
    "preds = {}\n",
    "preds, targets = plot_regression([('pcc', 'global', DGT),\n",
    "                            ('pcc', 'local', DGT),\n",
    "                           ('pcc', 'dual', DGT)],\n",
    "                           ['Global Pearson with DGT', 'Local Pearson with DGT', 'Dual Pearson with DGT'], stock_name='NVDA', fig_name='sp500_regression_NVDA.png', preds=preds)\n",
    "preds, targets = plot_regression([('pcc', 'global', DGT),\n",
    "                            ('pcc', 'local', DGT),\n",
    "                           ('pcc', 'dual', DGT)],\n",
    "                           ['Global Pearson with DGT', 'Local Pearson with DGT', 'Dual Pearson with DGT'], stock_name='JNJ', fig_name='sp500_regression_JNJ.png', preds=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([472, 256])\n"
     ]
    }
   ],
   "source": [
    "targets = torch.stack(targets, dim=1)\n",
    "print(targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Global Pearson with DGT', 'Local Pearson with DGT', 'Dual Pearson with DGT'])\n",
      "Global < Local < Dual MAE is true for 98, Global wins 117, Local wins 48, Dual wins 307\n",
      "Stocks when Global < Local < Dual MAE\n",
      "['AAL', 'ABT', 'ALB', 'AMCR', 'APA', 'APTV', 'ARE', 'BA', 'BALL', 'BAX', 'BBWI', 'BEN', 'BF-B', 'BIIB', 'BIO', 'BKR', 'BMY', 'BWA', 'BXP', 'C', 'CCI', 'CCL', 'CFG', 'CHTR', 'CLX', 'CPB', 'CPT', 'CTLT', 'CVS', 'CZR', 'D', 'DAL', 'DG', 'DIS', 'DOC', 'EL', 'ENPH', 'EPAM', 'EQR', 'ES', 'ESS', 'EW', 'EXPE', 'FIS', 'FMC', 'FRT', 'GE', 'GNRC', 'GPN', 'HAS', 'HOLX', 'HRL', 'INCY', 'INTC', 'IP', 'IVZ', 'KEY', 'KMX', 'LUV', 'LVS', 'MDT', 'MHK', 'MKTX', 'MMM', 'MOS', 'MTCH', 'MU', 'NCLH', 'NKE', 'NTRS', 'OXY', 'PARA', 'PAYC', 'PCG', 'PFE', 'PODD', 'RCL', 'SPG', 'SWK', 'SWKS', 'T', 'TAP', 'TDG', 'TFC', 'TFX', 'TGT', 'TPR', 'TSN', 'UAL', 'UDR', 'USB', 'VTR', 'VTRS', 'VZ', 'WDC', 'WYNN', 'ZBH', 'ZBRA']\n",
      "Stocks when Global wins\n",
      "['AAL', 'ABT', 'ALB', 'ALGN', 'AMCR', 'APA', 'APTV', 'ARE', 'AVB', 'BA', 'BALL', 'BAX', 'BBWI', 'BEN', 'BF-B', 'BIIB', 'BIO', 'BKR', 'BMY', 'BWA', 'BXP', 'C', 'CCI', 'CCL', 'CFG', 'CHTR', 'CLX', 'CNC', 'CPB', 'CPT', 'CRL', 'CTLT', 'CTSH', 'CVS', 'CZR', 'D', 'DAL', 'DG', 'DIS', 'DOC', 'EL', 'ENPH', 'EPAM', 'EQR', 'ES', 'ESS', 'EVRG', 'EW', 'EXPE', 'FFIV', 'FIS', 'FMC', 'FRT', 'GE', 'GM', 'GNRC', 'GPN', 'HAL', 'HAS', 'HOLX', 'HRL', 'HSIC', 'INCY', 'INTC', 'IP', 'IT', 'IVZ', 'KEY', 'KMX', 'LUV', 'LVS', 'MDT', 'MHK', 'MKC', 'MKTX', 'MMM', 'MOS', 'MSCI', 'MTCH', 'MU', 'NCLH', 'NKE', 'NTRS', 'OXY', 'PARA', 'PAYC', 'PCAR', 'PCG', 'PFE', 'PODD', 'RCL', 'SLB', 'SPG', 'STT', 'SWK', 'SWKS', 'T', 'TAP', 'TDG', 'TFC', 'TFX', 'TGT', 'TPR', 'TROW', 'TSN', 'UAL', 'UDR', 'UPS', 'USB', 'VTR', 'VTRS', 'VZ', 'WDC', 'WFC', 'WYNN', 'ZBH', 'ZBRA']\n",
      "Stocks when Local wins\n",
      "['AJG', 'AMP', 'AMT', 'ANET', 'APH', 'BKNG', 'CAG', 'CAT', 'CB', 'CHRW', 'CMG', 'COP', 'COST', 'CSX', 'DECK', 'DHI', 'DLTR', 'EIX', 'FANG', 'FAST', 'HIG', 'IFF', 'K', 'KR', 'LRCX', 'META', 'MLM', 'MPWR', 'NEM', 'NRG', 'NUE', 'OMC', 'ORCL', 'RL', 'SBAC', 'SCHW', 'SNA', 'SNPS', 'TEL', 'TT', 'ULTA', 'VMC', 'WAB', 'WBA', 'WBD', 'WMB', 'WMT', 'XOM']\n",
      "Stocks when Dual wins\n",
      "['A', 'AAPL', 'ABBV', 'ACGL', 'ACN', 'ADBE', 'ADI', 'ADM', 'ADP', 'ADSK', 'AEE', 'AEP', 'AES', 'AFL', 'AIG', 'AIZ', 'AKAM', 'ALL', 'ALLE', 'AMAT', 'AMD', 'AME', 'AMGN', 'AMZN', 'ANSS', 'AON', 'AOS', 'APD', 'ATO', 'AVGO', 'AVY', 'AWK', 'AXON', 'AXP', 'AZO', 'BAC', 'BBY', 'BDX', 'BG', 'BK', 'BLDR', 'BLK', 'BR', 'BRK-B', 'BRO', 'BSX', 'BX', 'CAH', 'CBOE', 'CBRE', 'CDNS', 'CDW', 'CE', 'CF', 'CHD', 'CI', 'CINF', 'CL', 'CMCSA', 'CME', 'CMI', 'CMS', 'CNP', 'COF', 'COO', 'COR', 'CPAY', 'CPRT', 'CRM', 'CSCO', 'CSGP', 'CTAS', 'CTRA', 'CVX', 'DD', 'DE', 'DFS', 'DGX', 'DHR', 'DLR', 'DOV', 'DPZ', 'DRI', 'DTE', 'DUK', 'DVA', 'DVN', 'DXCM', 'EA', 'EBAY', 'ECL', 'ED', 'EFX', 'EG', 'ELV', 'EMN', 'EMR', 'EOG', 'EQIX', 'EQT', 'ETN', 'ETR', 'EXC', 'EXPD', 'EXR', 'F', 'FCX', 'FDS', 'FDX', 'FE', 'FI', 'FICO', 'FITB', 'FSLR', 'FTNT', 'GD', 'GEN', 'GILD', 'GIS', 'GL', 'GLW', 'GOOG', 'GOOGL', 'GPC', 'GRMN', 'GS', 'GWW', 'HBAN', 'HCA', 'HD', 'HES', 'HII', 'HLT', 'HON', 'HPQ', 'HST', 'HSY', 'HUBB', 'HUM', 'IBM', 'ICE', 'IDXX', 'IEX', 'INTU', 'IPG', 'IQV', 'IRM', 'ISRG', 'ITW', 'J', 'JBHT', 'JBL', 'JCI', 'JKHY', 'JNJ', 'JNPR', 'JPM', 'KDP', 'KEYS', 'KIM', 'KKR', 'KLAC', 'KMB', 'KMI', 'KO', 'L', 'LDOS', 'LEN', 'LH', 'LHX', 'LIN', 'LKQ', 'LLY', 'LMT', 'LNT', 'LOW', 'LULU', 'LYB', 'LYV', 'MA', 'MAA', 'MAR', 'MAS', 'MCD', 'MCHP', 'MCK', 'MCO', 'MDLZ', 'MET', 'MGM', 'MMC', 'MNST', 'MO', 'MOH', 'MPC', 'MRK', 'MRO', 'MS', 'MSFT', 'MSI', 'MTB', 'MTD', 'NDAQ', 'NDSN', 'NEE', 'NFLX', 'NI', 'NOC', 'NOW', 'NSC', 'NTAP', 'NVDA', 'NVR', 'NWS', 'NWSA', 'NXPI', 'O', 'ODFL', 'OKE', 'ON', 'ORLY', 'PANW', 'PAYX', 'PEG', 'PEP', 'PFG', 'PG', 'PGR', 'PH', 'PHM', 'PKG', 'PLD', 'PM', 'PNC', 'PNR', 'PNW', 'POOL', 'PPG', 'PPL', 'PRU', 'PSA', 'PSX', 'PTC', 'PWR', 'QCOM', 'REG', 'REGN', 'RF', 'RJF', 'RMD', 'ROK', 'ROL', 'ROP', 'ROST', 'RSG', 'RTX', 'RVTY', 'SBUX', 'SHW', 'SJM', 'SMCI', 'SO', 'SPGI', 'SRE', 'STE', 'STLD', 'STX', 'STZ', 'SYF', 'SYK', 'SYY', 'TDY', 'TECH', 'TER', 'TJX', 'TMO', 'TMUS', 'TRGP', 'TRMB', 'TRV', 'TSCO', 'TSLA', 'TTWO', 'TXN', 'TXT', 'TYL', 'UHS', 'UNH', 'UNP', 'URI', 'V', 'VLO', 'VRSK', 'VRSN', 'VRTX', 'WAT', 'WEC', 'WELL', 'WM', 'WRB', 'WST', 'WTW', 'WY', 'XEL', 'XYL', 'YUM', 'ZTS']\n"
     ]
    }
   ],
   "source": [
    "maes = {}\n",
    "for key, results in preds.items():\n",
    "    results = torch.stack(results, dim=1)\n",
    "    maes[key] = [mae(res, y) for res, y in zip(results, targets)]\n",
    "\n",
    "print(maes.keys())\n",
    "\n",
    "g_count = []\n",
    "l_count = []\n",
    "d_count = []\n",
    "\n",
    "desired_count = []\n",
    "\n",
    "for i, (g, l, d) in enumerate(zip(*maes.values())):\n",
    "    if g < l and g < d and l < d:\n",
    "        desired_count.append(i)\n",
    "    if g < l and g < d:\n",
    "        g_count.append(i)\n",
    "    elif l < g and l < d:\n",
    "        l_count.append(i)\n",
    "    elif d < g and d < l:\n",
    "        d_count.append(i)\n",
    "\n",
    "\n",
    "print(f'Global < Local < Dual MAE is true for {len(desired_count)}, Global wins {len(g_count)}, Local wins {len(l_count)}, Dual wins {len(d_count)}')\n",
    "\n",
    "print(\"Stocks when Global < Local < Dual MAE\")\n",
    "print([(stock_names[i]) for i in desired_count])\n",
    "print(\"Stocks when Global wins\")\n",
    "print([(stock_names[i]) for i in g_count])\n",
    "print(\"Stocks when Local wins\")\n",
    "print([(stock_names[i]) for i in l_count])\n",
    "print(\"Stocks when Dual wins\")\n",
    "print([(stock_names[i]) for i in d_count])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stock",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
